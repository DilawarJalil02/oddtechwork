{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6642ac1",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.4) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\objdetect\\src\\cascadedetect.cpp:1689: error: (-215:Assertion failed) !empty() in function 'cv::CascadeClassifier::detectMultiScale'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-def85aa60050>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mgray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mfaces\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mface_cascade\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetectMultiScale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfaces\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m#         cv2.rectangle(img, (x,y), (x+w, y+h), (255, 0 , 0), 3)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.4) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\objdetect\\src\\cascadedetect.cpp:1689: error: (-215:Assertion failed) !empty() in function 'cv::CascadeClassifier::detectMultiScale'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('haarcascade_eye_tree_eyeglasses.xml')\n",
    "cap = cv2.VideoCapture(0)\n",
    "# biden_image = face_recognition.load_image_file(\"biden_obama.jpg\")\n",
    "while cap.isOpened():\n",
    "    _, img = cap.read()\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "    for (x, y , w ,h) in faces:\n",
    "#         cv2.rectangle(img, (x,y), (x+w, y+h), (255, 0 , 0), 3)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = img[y:y+h, x:x+w]\n",
    "#         cv2.imwrite(\"new1.png\", roi_color)\n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "#         print(eyes)\n",
    "        for (ex, ey ,ew, eh) in eyes:\n",
    "#             varr = (ex, ey ,ew, eh)\n",
    "            wav = cv2.rectangle(roi_color, (ex,ey), (ex+ew, ey+eh), (0, 255, 0), 5)\n",
    "#             print(wav)\n",
    "#             obama_face_encoding = face_recognition.face_encodings(wav)[0]\n",
    "#             print(obama_face_encoding)\n",
    "            cv2.imwrite('new3.png',cv2.rectangle(roi_color, (ex,ey), (ex+ew, ey+eh), (0, 255, 0), 5))\n",
    "    # Display the output\n",
    "#     cv2.imwrite('img.png', img)\n",
    "    cv2.imshow('img', img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fbca07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('haarcascade_eye_tree_eyeglasses.xml')\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    _, img = cap.read()\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "\n",
    "    for (x, y , w ,h) in faces:\n",
    "        cv2.rectangle(img, (x,y), (x+w, y+h), (255, 0 , 0), 3)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = img[y:y+h, x:x+w]\n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "        for (ex, ey ,ew, eh) in eyes:\n",
    "            cv2.rectangle(roi_color, (ex,ey), (ex+ew, ey+eh), (0, 255, 0), 5)\n",
    "\n",
    "    # Display the output\n",
    "    cv2.imshow('img', img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29a23ef",
   "metadata": {},
   "source": [
    "# Computer Vision for Eye Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a456c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('haarcascade_eye_tree_eyeglasses.xml')\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "frame = cv2.flip(frame, 1)\n",
    "\n",
    "detector.find_eyes(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c790ea68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('haarcascade_eye_tree_eyeglasses.xml')\n",
    "\n",
    "def detectFace(bgr_image):\n",
    "    gray_image = cv2.cvtColor(bgr_image, cv2.COLOR_BGR2GRAY)\n",
    "    return face_cascade.detectMultiScale(gray_image, 1.3, 5)\n",
    "\n",
    "def detectEyes(bgr_image):\n",
    "    gray_image = cv2.cvtColor(bgr_image, cv2.COLOR_BGR2GRAY)\n",
    "    return eye_cascade.detectMultiScale(gray_image, 1.3, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e614ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector_params = cv2.SimpleBlobDetector_Params()\n",
    "detector_params.filterByArea = True\n",
    "detector_params.maxArea = 1400\n",
    "blobDetector = cv2.SimpleBlobDetector_create(detector_params)\n",
    "\n",
    "def detectPupils(bgr_image, threshold=127):\n",
    "    img = cv2.copyTo(bgr_image, None)\n",
    "    img[0:int(img.shape[0] / 4), 0:img.shape[1]] = (255, 255, 255)\n",
    "    gray_frame = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    _, t_img = cv2.threshold(gray_frame, threshold, 255, cv2.THRESH_BINARY)\n",
    "    img = cv2.erode(t_img, None, iterations=2)\n",
    "    img = cv2.dilate(img, None, iterations=4)\n",
    "    img = cv2.medianBlur(img, 5)\n",
    "    return blobDetector.detect(img), t_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c97faa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2bd48321",
   "metadata": {},
   "source": [
    "# Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8aa466b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from os.path import realpath, normpath\n",
    "\n",
    "class CascadeDetector:\n",
    "    def __init__(self):\n",
    "#         xml_path = normpath(realpath(cv2.__file__) + '../../../../Library/etc/haarcascades/')\n",
    "        #self.face_cascade = cv2.CascadeClassifier(\n",
    "            #'C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\EyePaint\\\\Library\\\\etc\\\\haarcascades\\\\haarcascade_frontalface_default.xml')\n",
    "        #self.eye_cascade = cv2.CascadeClassifier(\n",
    "            #'C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\EyePaint\\\\Library\\\\etc\\\\haarcascades\\\\haarcascade_eye.xml')\n",
    "#         self.face_cascade = cv2.CascadeClassifier(xml_path + '/haarcascade_frontalface_default.xml')\n",
    "        self.face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "#         self.eye_cascade = cv2.CascadeClassifier(xml_path + '/haarcascade_eye.xml')\n",
    "        self.eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "        detector_params = cv2.SimpleBlobDetector_Params()\n",
    "        detector_params.filterByArea = True\n",
    "        detector_params.maxArea = 1500\n",
    "        self.blobDetector = cv2.SimpleBlobDetector_create(detector_params)\n",
    "        self.PUPIL_THRESH = cv2.getTrackbarPos('Threshold', 'EyePaint')\n",
    "        self.face_frame = None\n",
    "        self.previous_face = [0, 0, 0, 0]\n",
    "        self.previous_left_eye = [-1, 0, 0, 0]\n",
    "        self.previous_right_eye = [-1, 0, 0, 0]\n",
    "        self.left_eye_frame = None\n",
    "        self.right_eye_frame = None\n",
    "        self.lp_frame = None\n",
    "        self.rp_frame = None\n",
    "        self.lp_thresh_frame = None\n",
    "        self.rp_thresh_frame = None\n",
    "        self.move_thresh = 0.4\n",
    "        self.left_pupil = [0, 0]\n",
    "        self.right_pupil = [0, 0]\n",
    "        self.tmp_left_pupil = [0, 0]\n",
    "        self.tmp_right_pupil = [0, 0]\n",
    "        self.phase = 0\n",
    "        self.left_is_visible = False\n",
    "        self.right_is_visible = False\n",
    "        self.overlap_threshold = 0.9\n",
    "\n",
    "    def detectFace(self, bgr_image):\n",
    "        self.PUPIL_THRESH = cv2.getTrackbarPos('Eye Detection Threshold', 'EyePaint')\n",
    "        gray_image = cv2.cvtColor(bgr_image, cv2.COLOR_BGR2GRAY)\n",
    "        return self.face_cascade.detectMultiScale(gray_image, 1.3, 5)  # TODO: parametrizzare parametri\n",
    "\n",
    "    def detectEyes(self, bgr_image):\n",
    "        gray_image = cv2.cvtColor(bgr_image, cv2.COLOR_BGR2GRAY)\n",
    "        return self.eye_cascade.detectMultiScale(gray_image, 1.3, 5)  # TODO: parametrizzare parametri\n",
    "\n",
    "    def detectPupils(self, bgr_image, threshold=127):\n",
    "        img = cv2.copyTo(bgr_image, None)\n",
    "        img[0:int(img.shape[0] / 4), 0:img.shape[1]] = (255, 255, 255)\n",
    "        gray_frame = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        _, t_img = cv2.threshold(gray_frame, threshold, 255, cv2.THRESH_BINARY)\n",
    "        img = cv2.erode(t_img, None, iterations=2)\n",
    "        img = cv2.dilate(img, None, iterations=4)\n",
    "        img = cv2.medianBlur(img, 5)\n",
    "        return self.blobDetector.detect(img), t_img\n",
    "\n",
    "    def find_eyes(self, frame):\n",
    "        self.PUPIL_THRESH = cv2.getTrackbarPos('Eye Detection Threshold', 'EyePaint')\n",
    "\n",
    "        frame_w = frame.shape[1]\n",
    "        frame_h = frame.shape[0]\n",
    "        frame_ratio = frame_w / frame_h\n",
    "        frame_original = cv2.copyTo(frame, None)\n",
    "\n",
    "        faces = self.detectFace(frame)\n",
    "        for (x, y, w, h) in faces:\n",
    "            face_w = int(frame_w / 3)\n",
    "            face_h = int(face_w / frame_ratio)\n",
    "            face_x = int(x + w / 2 - face_w / 2)\n",
    "            face_y = int(y + h / 2 - face_h / 2)\n",
    "            self.face_frame = frame_original[face_y:face_y + face_h, face_x:face_x + face_w]\n",
    "            x, y, w, h = self.stabilize_face_frame(x, y, w, h)\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 255, 0), 2)\n",
    "\n",
    "            frame[0:y, 0:frame.shape[1]] = cv2.GaussianBlur(frame[0:y, 0:frame.shape[1]], (0, 0), 4)\n",
    "            frame[y:y+h, 0:x] = cv2.GaussianBlur(frame[y:y+h, 0:x], (0, 0), 4)\n",
    "            frame[y+h:frame.shape[0], 0:frame.shape[1]] = cv2.GaussianBlur(frame[y+h:frame.shape[0], 0:frame.shape[1]], (0, 0), 4)\n",
    "            frame[y:y+h, x+w:frame.shape[1]] = cv2.GaussianBlur(frame[y:y+h, x+w:frame.shape[1]], (0, 0), 4)\n",
    "\n",
    "            eyes = self.detectEyes(self.face_frame)\n",
    "            self.left_is_visible = False\n",
    "            self.right_is_visible = False\n",
    "            for (ex, ey, ew, eh) in eyes:\n",
    "                if ey + eh > face_h / 2:\n",
    "                    pass\n",
    "                if ex + ew / 2 < face_w / 2:\n",
    "                    # Left eye\n",
    "                    self.left_is_visible = True\n",
    "                    ex, ey, ew, eh, self.previous_left_eye = self.stabilize_eyes_frame(face_x, face_y, ex, ey, ew,\n",
    "                                                                                       eh, self.previous_left_eye)\n",
    "\n",
    "                    cv2.rectangle(frame, (face_x + ex, face_y + ey), (face_x + ex + ew, face_y + ey + eh),\n",
    "                                  (255, 0, 255), 2)\n",
    "                    if self.phase>0:\n",
    "                        cv2.rectangle(self.face_frame, (ex, ey), (ex + ew, ey + eh), (255, 0, 255), 2)\n",
    "                    self.left_eye_frame = self.face_frame[ey:ey + eh, ex:ex + ew]\n",
    "                    lp_keypoint, lt_img = self.detectPupils(self.left_eye_frame, self.PUPIL_THRESH)\n",
    "                    self.lp_thresh_frame = cv2.cvtColor(lt_img, cv2.COLOR_GRAY2BGR)\n",
    "                    self.lp_frame = cv2.copyTo(self.lp_thresh_frame, None)\n",
    "                    self.lp_frame = cv2.drawKeypoints(self.lp_frame, lp_keypoint,\n",
    "                                                      self.lp_frame,\n",
    "                                                      (0, 255, 0), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "                    if len(lp_keypoint) > 0:\n",
    "                        self.tmp_left_pupil = [int(lp_keypoint[0].pt[0]), int(lp_keypoint[0].pt[1])]\n",
    "                        frame = cv2.circle(frame, (face_x + ex + self.left_pupil[0], face_y + ey + self.left_pupil[1]),\n",
    "                                           5,\n",
    "                                           (0, 255, 0), 4)\n",
    "                        self.face_frame = cv2.circle(self.face_frame,\n",
    "                                           (ex + self.left_pupil[0], ey + self.left_pupil[1]), 5,\n",
    "                                           (0, 255, 0), 4)\n",
    "                        # self.left_pupil = [face_x + ex + int(ew / 2), face_y + ey + int(eh / 2)]\n",
    "                    else:\n",
    "                        self.tmp_left_pupil = [face_x + ex + int(ew / 2), face_y + ey + int(eh / 2)]\n",
    "                else:\n",
    "                    # Right\n",
    "                    self.right_is_visible = True\n",
    "                    ex, ey, ew, eh, self.previous_right_eye = self.stabilize_eyes_frame(face_x, face_y, ex, ey, ew,\n",
    "                                                                                          eh, self.previous_right_eye)\n",
    "                    cv2.rectangle(frame, (face_x + ex, face_y + ey), (face_x + ex + ew, face_y + ey + eh),\n",
    "                                  (255, 0, 255), 2)\n",
    "                    if self.phase>0:\n",
    "                        cv2.rectangle(self.face_frame, (ex, ey), (ex + ew, ey + eh), (255, 0, 255), 2)\n",
    "                    self.right_eye_frame = self.face_frame[ey:ey + eh, ex:ex + ew]\n",
    "                    rp_keypoint, rt_img = self.detectPupils(self.right_eye_frame, self.PUPIL_THRESH)\n",
    "                    self.rp_thresh_frame = cv2.cvtColor(rt_img, cv2.COLOR_GRAY2BGR)\n",
    "                    self.rp_frame = cv2.copyTo(self.rp_thresh_frame, None)\n",
    "                    self.rp_frame = cv2.drawKeypoints(self.rp_frame, rp_keypoint,\n",
    "                                                      self.rp_frame,\n",
    "                                                      (0, 255, 0), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "                    if len(rp_keypoint) > 0:\n",
    "                        self.tmp_right_pupil = [int(rp_keypoint[0].pt[0]), int(rp_keypoint[0].pt[1])]\n",
    "                        frame = cv2.circle(frame,\n",
    "                                           (face_x + ex + self.right_pupil[0], face_y + ey + self.right_pupil[1]), 5,\n",
    "                                           (0, 255, 0), 4)\n",
    "                        self.face_frame = cv2.circle(self.face_frame,\n",
    "                                           (ex + self.right_pupil[0], ey + self.right_pupil[1]), 5,\n",
    "                                           (0, 255, 0), 4)\n",
    "                        # self.right_pupil = [face_x + ex + int(ew / 2), face_y + ey + int(eh / 2)]\n",
    "                    else:\n",
    "                        self.tmp_right_pupil = [face_x + ex + int(ew / 2), face_y + ey + int(eh / 2)]\n",
    "        self.check_eyes()\n",
    "        return frame\n",
    "\n",
    "    def check_eyes(self):\n",
    "        if cv2.norm(np.array(self.tmp_right_pupil, np.int32), np.array(self.right_pupil, np.int32)) > self.move_thresh \\\n",
    "                and cv2.norm(np.array(self.tmp_left_pupil, np.int32),\n",
    "                             np.array(self.left_pupil, np.int32)) > self.move_thresh:\n",
    "            self.right_pupil = self.tmp_right_pupil\n",
    "            self.left_pupil = self.tmp_left_pupil\n",
    "\n",
    "    def stabilize_face_frame(self, x, y, w, h):\n",
    "        prev_norm = cv2.norm(np.array([x, y, w, h], np.float32), np.array(self.previous_face, np.float32))\n",
    "        if prev_norm > 60:\n",
    "            self.previous_face = [x, y, w, h]\n",
    "\n",
    "        else:\n",
    "            x = self.previous_face[0]\n",
    "            y = self.previous_face[1]\n",
    "            w = self.previous_face[2]\n",
    "            h = self.previous_face[3]\n",
    "\n",
    "        return x, y, w, h\n",
    "\n",
    "    def stabilize_eyes_frame(self, face_x, face_y, x, y, w, h, previous_eyes_coords):\n",
    "        if self.check_overlap_area(face_x + x, face_y + y, w, h, previous_eyes_coords) or previous_eyes_coords[0] == -1:\n",
    "            previous_eyes_coords = [face_x + x, face_y + y, w, h]\n",
    "\n",
    "        else:\n",
    "            x = previous_eyes_coords[0] - face_x\n",
    "            y = previous_eyes_coords[1] - face_y\n",
    "            w = previous_eyes_coords[2]\n",
    "            h = previous_eyes_coords[3]\n",
    "\n",
    "        return x, y, w, h, previous_eyes_coords\n",
    "\n",
    "    def check_overlap_area(self, x, y, w, h, previous_eyes_coords):\n",
    "\n",
    "        px = previous_eyes_coords[0]\n",
    "        py = previous_eyes_coords[1]\n",
    "        pw = previous_eyes_coords[2]\n",
    "        ph = previous_eyes_coords[3]\n",
    "\n",
    "        over_x1 = x if x < px else px\n",
    "        over_y1 = y if y < py else py\n",
    "        over_x2 = (x + w) if x + w > px + pw else px + pw\n",
    "        over_y2 = (y + h) if y + h > py + ph else py + ph\n",
    "\n",
    "        overlap_area = (over_x2 - over_x1) * (over_y2 - over_y1)\n",
    "        actual_area = w * h\n",
    "\n",
    "        overlap_rate = actual_area / overlap_area\n",
    "        return overlap_rate < self.overlap_threshold\n",
    "\n",
    "    def get_images(self):\n",
    "        images = {\n",
    "            \"face_frame\": self.face_frame,\n",
    "            \"left_eye_frame\": self.left_eye_frame,\n",
    "            \"right_eye_frame\": self.right_eye_frame,\n",
    "            \"lp_thresh_frame\": self.lp_thresh_frame,\n",
    "            \"rp_thresh_frame\": self.rp_thresh_frame,\n",
    "            \"lp_frame\": self.lp_frame,\n",
    "            \"rp_frame\": self.rp_frame\n",
    "        }\n",
    "\n",
    "        return images\n",
    "\n",
    "    def start_phase(self, phase, threshold=0.95):\n",
    "        self.phase = phase\n",
    "        self.overlap_threshold = threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4665c85a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "023b3c46",
   "metadata": {},
   "source": [
    "# Capture Eyes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a02c453",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "image = cv2.imread('oddTech_1.jpg')\n",
    "eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "eye = eye_cascade.detectMultiScale(image)\n",
    "for (x,y,w,h) in eye:\n",
    "    eye = image[y : y+h , x : x+w]\n",
    "    cv2.imshow('eye', eye)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0448c339",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'outfile' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-b76b8368faab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;31m#cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meyes_roi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'outfile' is not defined"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "image = cv2.imread('oddTech_1.jpg')\n",
    "eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "eye = eye_cascade.detectMultiScale(image)\n",
    "for x,y,w,h in eye:\n",
    "    roi_gray = gray[y:y+h, x:x+w]\n",
    "    roi_color = img[y:y+h, x:x+w]\n",
    "    eyes = eyePair_cascade.detectMultiScale(roi_gray)   \n",
    "#     if len(eyes) == 0:\n",
    "#         return   \n",
    "    for (ex,ey,ew,eh) in eyes:\n",
    "        eyes_roi = roi_color[ey: ey+eh, ex:ex + ew]\n",
    "        #cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "\n",
    "cv2.imwrite(outfile, eyes_roi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84d7df3",
   "metadata": {},
   "source": [
    "# Eye Pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb214df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import cv2\n",
    "\n",
    "# face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_alt.xml')\n",
    "# eyePair_cascade = cv2.CascadeClassifier('haarcascade_mcs_eyepair_big.xml')\n",
    "\n",
    "# def return_eye_pair(infile, outfile):\n",
    "#     img = cv2.imread(infile)\n",
    "#     gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "#     faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "#     if len(faces) == 0: return\n",
    "#     for x,y,w,h in faces:\n",
    "#         roi_gray = gray[y:y+h, x:x+w]\n",
    "#         roi_color = img[y:y+h, x:x+w]\n",
    "#         eyes = eyePair_cascade.detectMultiScale(roi_gray)\n",
    "#         if len(eyes) == 0: return\n",
    "#         for (ex,ey,ew,eh) in eyes:\n",
    "#             eyes_roi = roi_color[ey: ey+eh, ex:ex + ew]\n",
    "#             #cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "\n",
    "#     cv2.imwrite(outfile, eyes_roi)\n",
    "\n",
    "# def main():\n",
    "#     return_eye_pair('Lenna.png', 'eye_pair.jpg')\n",
    "    \n",
    "# if __name__ == '__main__':\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9b539de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_alt.xml')\n",
    "eyePair_cascade = cv2.CascadeClassifier('haarcascade_mcs_eyepair_big.xml')\n",
    "\n",
    "def return_eye_pair(infile, outfile):\n",
    "    img = cv2.imread(infile)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    if len(faces) == 0: return\n",
    "    for x,y,w,h in faces:\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = img[y:y+h, x:x+w]\n",
    "        eyes = eyePair_cascade.detectMultiScale(roi_gray)\n",
    "        if len(eyes) == 0: return\n",
    "        for (ex,ey,ew,eh) in eyes:\n",
    "            eyes_roi = roi_color[ey: ey+eh, ex:ex + ew]\n",
    "            #cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "\n",
    "    cv2.imwrite(outfile, eyes_roi)\n",
    "\n",
    "# def main():\n",
    "#     return_eye_pair('Lenna.png', 'eye_pair.jpg')\n",
    "    \n",
    "# if __name__ == '__main__':\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e849c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "return_eye_pair('oddTech_1.jpg', 'ahmed_eye_pair.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3d243b",
   "metadata": {},
   "source": [
    "# testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e9ec9d3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_alt.xml')\n",
    "eyePair_cascade = cv2.CascadeClassifier('haarcascade_mcs_eyepair_big.xml')\n",
    "\n",
    "img = cv2.imread('dilawar_new.jpeg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "# cv2.imshow('img', img)\n",
    "faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "# if len(faces) == 0:\n",
    "#     return\n",
    "for x,y,w,h in faces:\n",
    "    roi_gray = gray[y:y+h, x:x+w]\n",
    "    roi_color = img[y:y+h, x:x+w]\n",
    "    eyes = eyePair_cascade.detectMultiScale(roi_gray)\n",
    "#     if len(eyes) == 0:\n",
    "#         return\n",
    "    for (ex,ey,ew,eh) in eyes:\n",
    "#         ey= 300 #520\n",
    "#         print('ey:', ey, 'eh:', eh, 'ex:', ex, 'ew:', ew)\n",
    "        ey= round(ey/2) #520\n",
    "        eh= eh+eh+round(eh/2) #216 \n",
    "        ex= round(ex/2) #329 \n",
    "        ew= ew+round(ew/3) #883\n",
    "        eyes_roi = roi_color[ey: ey+eh, ex:ex + ew]\n",
    "        #cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "\n",
    "cv2.imwrite('dilawar_new_eye_pair_1.jpeg', eyes_roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "475b5359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "260"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(ey/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b27eb30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "432"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eh+eh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f565a8cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "164"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(ex/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c02a11d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1766"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ew+ew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e141f53e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ece60fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "13f89110",
   "metadata": {},
   "source": [
    "# Eye Pair Working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b7d959c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "image = cv2.imread('images/with_mask/abdullah_mask.jpeg')\n",
    "# image = cv2.imread('images/with_mask/dilawar_mask.jpeg')\n",
    "# image = cv2.imread('images/with_mask/dilawar_mask_croped.jpeg')\n",
    "# image = cv2.imread('images/with_mask/owais_mask.jpeg')\n",
    "# image = cv2.imread('images/with_mask/furqan_mask.jpeg')\n",
    "# image = cv2.imread('images/with_mask/aqib_mask.jpeg')\n",
    "# image = cv2.imread('images/with_mask/ismail_mask.jpeg')\n",
    "# image = cv2.imread('images/with_mask/ismail_mask_croped.jpeg')\n",
    "# image = cv2.imread('images/with_mask/sohaib_mask.jpeg')\n",
    "# image = cv2.imread('images/with_mask/sohaib_mask_croped.jpeg')\n",
    "# image = cv2.imread('images/with_mask/a_saboor_mask.jpeg')\n",
    "# image = cv2.imread('images/with_mask/a_saboor_mask_glasses.jpeg')\n",
    "\n",
    "eyePair_cascade = cv2.CascadeClassifier('cv_haarcascades/haarcascade_mcs_eyepair_big.xml')\n",
    "eye = eyePair_cascade.detectMultiScale(image)\n",
    "for (x,y,w,h) in eye:\n",
    "#     print('y:', y, 'h:', h, 'x:', x, 'w:', w)\n",
    "#     y= round(y/2) #520\n",
    "#     h= h+h+round(h/2) #216\n",
    "#     x= round(x/2) #329\n",
    "#     w= w+round(w/3) #883\n",
    "\n",
    "    y= y-100 #613  500 = 113\n",
    "    h= h+150 #114  250 = 136\n",
    "    x= x-50 #186 100 = 86\n",
    "    w= w+100 #468  650 = 182\n",
    "    \n",
    "#     eye = image[y : ey+eh , x : ex+ew]\n",
    "    eye = image[y : y+h , x : x+w]\n",
    "    \n",
    "#     cv2.imwrite('abdullah_mask_eye_pair_4.jpeg', eye)\n",
    "    cv2.imshow('eye', eye)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2de92403",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "image = cv2.imread(r'Z:\\Abdullah\\Working_dir\\Abdullah_dir\\Face_Recognition\\identify_and_draw_boxes_on_faces\\train_dir\\oddTech_6.jpg')\n",
    "eyePair_cascade = cv2.CascadeClassifier('cv_haarcascades/haarcascade_mcs_eyepair_big.xml')\n",
    "eye = eyePair_cascade.detectMultiScale(image)\n",
    "for (x,y,w,h) in eye:\n",
    "    y= y-100\n",
    "    h= h+150\n",
    "    x= x-50\n",
    "    w= w+100\n",
    "    eye = image[y : y+h , x : x+w]\n",
    "#     file_name = path_to_save_image+img_path.split('/')[-1].split('.')[0]+'_eye_pair.jpeg'\n",
    "# #     cv2.imwrite('images/eye_pair_generated/abdullah_mask_eye_pair.jpeg', eye)\n",
    "#     cv2.imwrite(file_name, eye)\n",
    "    cv2.imshow('eye', eye)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5531b11",
   "metadata": {},
   "source": [
    "# Eye Pair Working Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6b8f3a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# path_of_image = 'images/with_mask/abdullah_mask.jpeg'\n",
    "\n",
    "def eye_pair_from_image(path_of_images, path_to_save_image=''):\n",
    "    images_list = os.listdir(path_of_images)\n",
    "    \n",
    "    for img in images_list:\n",
    "        path_of_single_image = path_of_images+'/'+img\n",
    "\n",
    "        image = cv2.imread(path_of_single_image)\n",
    "        eyePair_cascade = cv2.CascadeClassifier('cv_haarcascades/haarcascade_mcs_eyepair_big.xml')\n",
    "        eye = eyePair_cascade.detectMultiScale(image)\n",
    "        for (x,y,w,h) in eye:\n",
    "            y= y-100\n",
    "            h= h+150\n",
    "            x= x-50\n",
    "            w= w+90\n",
    "            eye = image[y : y+h , x : x+w]\n",
    "\n",
    "            file_name_to_save = path_to_save_image+path_of_single_image.split('/')[-1].split('.')[0]+'_eye_pair.jpeg'\n",
    "            cv2.imwrite(file_name_to_save, eye)\n",
    "\n",
    "#     cv2.imwrite('abdullah_mask_eye_pair.jpeg', eye)\n",
    "# img_path.split('/')[-1].split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2c3f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_of_image = 'images/with_mask/'\n",
    "path_of_image = 'images/eye_pair_generated/'\n",
    "\n",
    "eye_pair_from_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dacb07e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#     path_of_image = 'images/with_mask/'+img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c86574e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# images_list = os.listdir(r'images\\with_mask')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ed3c8cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for img in images_list:\n",
    "#     path_of_image = 'images/with_mask/'+img\n",
    "#     eye_pair_from_image(path_of_image,'images/eye_pair_generated/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a798649",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293f130e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z:\\Abdullah\\Working_dir\\Abdullah_dir\\Face_Recognition\\identify_and_draw_boxes_on_faces\\train_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3626a9",
   "metadata": {},
   "source": [
    "# Function Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "96899cd0",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.4) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgcodecs\\src\\loadsave.cpp:799: error: (-215:Assertion failed) !_img.empty() in function 'cv::imwrite'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-01019cb99c7e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m eye_pair_from_image(r'Z:\\Abdullah\\Working_dir\\Abdullah_dir\\Face_Recognition\\identify_and_draw_boxes_on_faces\\train_dir',\n\u001b[0m\u001b[0;32m      2\u001b[0m                    'images/eye_pair_generated/')\n",
      "\u001b[1;32m<ipython-input-42-7628fc42259c>\u001b[0m in \u001b[0;36meye_pair_from_image\u001b[1;34m(path_of_images, path_to_save_image)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[0mfile_name_to_save\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpath_to_save_image\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mpath_of_single_image\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'_eye_pair.jpeg'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m             \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name_to_save\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meye\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;31m#     cv2.imwrite('abdullah_mask_eye_pair.jpeg', eye)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.4) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgcodecs\\src\\loadsave.cpp:799: error: (-215:Assertion failed) !_img.empty() in function 'cv::imwrite'\n"
     ]
    }
   ],
   "source": [
    "# eye_pair_from_image(r'Z:\\Abdullah\\Working_dir\\Abdullah_dir\\Face_Recognition\\identify_and_draw_boxes_on_faces\\train_dir',\n",
    "#                    'images/eye_pair_generated/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e302ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db0c66f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "247ef993",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'eyes_roi' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-e59f115da490>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;31m#cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'abdullah_mask_eyes_pair_4.jpeg'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meyes_roi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'eyes_roi' is not defined"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "image = cv2.imread('owais_mask.jpeg')\n",
    "eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "eyePair_cascade = cv2.CascadeClassifier('haarcascade_mcs_eyepair_big.xml')\n",
    "\n",
    "eye = eye_cascade.detectMultiScale(image)\n",
    "for x,y,w,h in eye:\n",
    "    roi_gray = gray[y:y+h, x:x+w]\n",
    "    roi_color = img[y:y+h, x:x+w]\n",
    "    eyes = eyePair_cascade.detectMultiScale(roi_gray)   \n",
    "#     if len(eyes) == 0:\n",
    "#         return   \n",
    "    for (ex,ey,ew,eh) in eyes:\n",
    "        eyes_roi = roi_color[ey: ey+eh, ex:ex + ew]\n",
    "        #cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "\n",
    "cv2.imwrite('abdullah_mask_eyes_pair_4.jpeg', eyes_roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "350de080",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "eyePair_cascade = cv2.CascadeClassifier('haarcascade_mcs_eyepair_big.xml')\n",
    "\n",
    "def return_eye_pair_with_mask(infile, outfile):\n",
    "    img = cv2.imread(infile)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "    eye = eye_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    if len(eye) == 0: return\n",
    "    for x,y,w,h in eye:\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = img[y:y+h, x:x+w]\n",
    "        eyes = eyePair_cascade.detectMultiScale(roi_gray)\n",
    "        if len(eyes) == 0: return\n",
    "        for (ex,ey,ew,eh) in eyes:\n",
    "            eyes_roi = roi_color[ey: ey+eh, ex:ex + ew]\n",
    "            #cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "\n",
    "    cv2.imwrite(outfile, eyes_roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b1e8525",
   "metadata": {},
   "outputs": [],
   "source": [
    "return_eye_pair_with_mask('dilawar_mask.jpeg', 'dilawar_mask_eyes_pair_2.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4de78f68",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'roi_color' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-b0b0654aed1f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mex\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mex\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#329\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0mew\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mew\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mew\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#883\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m     \u001b[0meyes_roi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroi_color\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mey\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0meh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mex\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mex\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mew\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m     \u001b[1;31m#cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'roi_color' is not defined"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "import cv2\n",
    "\n",
    "# face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_alt.xml')\n",
    "eyePair_cascade = cv2.CascadeClassifier('haarcascade_mcs_eyepair_big.xml')\n",
    "\n",
    "img = cv2.imread('abdullah_mask.jpeg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "# cv2.imshow('img', img)\n",
    "# faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "# if len(faces) == 0:\n",
    "#     return\n",
    "# for x,y,w,h in faces:\n",
    "#     roi_gray = gray[y:y+h, x:x+w]\n",
    "#     roi_color = img[y:y+h, x:x+w]\n",
    "eyes = eyePair_cascade.detectMultiScale(gray)\n",
    "#     if len(eyes) == 0:\n",
    "#         return\n",
    "for (ex,ey,ew,eh) in eyes:\n",
    "#         ey= 300 #520\n",
    "#         print('ey:', ey, 'eh:', eh, 'ex:', ex, 'ew:', ew)\n",
    "    ey= round(ey/2) #520\n",
    "    eh= eh+eh+round(eh/2) #216 \n",
    "    ex= round(ex/2) #329 \n",
    "    ew= ew+round(ew/3) #883\n",
    "    eyes_roi = roi_color[ey: ey+eh, ex:ex + ew]\n",
    "    #cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "\n",
    "cv2.imwrite('abdullah_mask_eye_pair_3.jpeg', eyes_roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7872b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d858e900",
   "metadata": {},
   "source": [
    "# Eye Pair Detect (Usama Bhai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1371637",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('haarcascade_eye_tree_eyeglasses.xml')\n",
    "cap = cv2.VideoCapture(0)\n",
    "# biden_image = face_recognition.load_image_file(\"biden_obama.jpg\")\n",
    "while cap.isOpened():\n",
    "    _, img = cap.read()\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "    for (x, y , w ,h) in faces:\n",
    "#         cv2.rectangle(img, (x,y), (x+w, y+h), (255, 0 , 0), 3)\n",
    "        h2 = h-90\n",
    "        y2 = y + 30\n",
    "        roi_gray = gray[y:y2+h2, x:x+w]\n",
    "        roi_color = img[y:y2+h2, x:x+w]\n",
    "#         cv2.imwrite(\"new1.png\", roi_color)\n",
    "        cv2.rectangle(img, (x,y), (x+w, y2+h2), (255, 0 , 0), 3)\n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "#         print(eyes)\n",
    "        for (ex, ey ,ew, eh) in eyes:\n",
    "            roi_color2 = roi_color[ey:ey+eh, ex:ex+ew]\n",
    "#             varr = (ex, ey ,ew, eh)\n",
    "            cv2.rectangle(roi_color, (ex,ey), (ex+ew, ey+eh), (0, 255, 0), 5)\n",
    "#             print(wav)\n",
    "#             obama_face_encoding = face_recognition.face_encodings(wav)[0]\n",
    "#             print(obama_face_encoding)\n",
    "#         cv2.imwrite('eye_detection.png',cv2.rectangle(roi_color, (ex,ey), (ex+ew, ey+eh), (0, 255, 0), 5))\n",
    "#         cv2.imwrite('23.png',roi_color)\n",
    "    # Display the output\n",
    "#     cv2.imwrite('img.png', img)\n",
    "    cv2.imshow('img', img)\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ce4422",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
